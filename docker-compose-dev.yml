services:
  caddy:
    image: caddy:alpine
    restart: always
    env_file:
      - .env
    ports:
      - "${ROOT_HTTP_PORT:-80}:80"
      - "${ROOT_HTTPS_PORT:-443}:443"
    volumes:
      - ./Caddyfile/dev:/etc/caddy/Caddyfile
    command: caddy run --config /etc/caddy/Caddyfile

  minio:
    container_name: minio
    image: minio/minio:latest
    volumes:
      - minio_data_volume:/data
    environment:
      - MINIO_ROOT_USER
      - MINIO_ROOT_PASSWORD
      - MINIO_BROWSER_REDIRECT_URL=http://localhost:${ROOT_HTTP_PORT}/minio-console
    expose:
      - "9000" # minio
      - "9001" # minio console
    command: server data --address ':9000' --console-address ':9001'
    shm_size: "1gb"

  createbuckets:
    image: minio/mc
    volumes:
      - minio_data_volume:/data
    depends_on:
      - minio
    entrypoint: >
      /bin/sh -c \ "/usr/bin/mc config host add minio http://minio:9000 ${MINIO_ROOT_USER} ${MINIO_ROOT_PASSWORD}; \ /usr/bin/mc mb data/loki; /usr/bin/mc mb data/tempo; /usr/bin/mc anonymous set public data/tempo; \ /usr/bin/mc anonymous set public data/loki; \ exit 0;"

  fluent-bit:
    image: fluent/fluent-bit:latest
    container_name: fluent-bit
    volumes:
      - /var/lib/docker/containers:/var/lib/docker/containers:ro
      - ./exporters/fluent-bit/fluent-bit.conf:/fluent-bit/etc/fluent-bit.conf:ro
      - ./exporters/fluent-bit/parsers.conf:/fluent-bit/etc/parsers.conf:ro

  loki:
    image: grafana/loki:latest
    container_name: loki
    environment:
      - MINIO_ROOT_PASSWORD
      - MINIO_ROOT_USER
      - MINIO_BUCKET_NAME=loki
    expose:
      - "3100"
    volumes:
      - "./backends/loki:/etc/loki"
    command: -config.file=/etc/loki/loki-config.yml -config.expand-env=true
    depends_on:
      - minio
    restart: always

  prometheus:
    image: prom/prometheus:latest
    container_name: prometheus
    expose:
      - "9090"
    volumes:
      - "./backends/prometheus:/etc/prometheus"
      - prometheus_data_volume:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus-config.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/usr/share/prometheus/console_libraries'
      - '--web.console.templates=/usr/share/prometheus/consoles'
    restart: always

  alertmanager:
    image: prom/alertmanager
    container_name: alertmanager
    volumes:
      - "./etc/alertmanager:/etc/alertmanager"
    command:
      - '--config.file=/etc/alertmanager/config.yml'
    expose:
      - "9093"
    restart: always

  prometheus-msteams:
    image: docker.io/bzon/prometheus-msteams:v1.1.4
    container_name: prometheus-msteams
    restart: always
    environment:
      - TEAMS_INCOMING_WEBHOOK_URL=${MS_WEBHOOK_URL}
      - TEAMS_REQUEST_URI=alertmanager
    expose:
      - "2000"

  # check-instance:
  #   build: ./etc/check-instance
  #   environment:
  #     - WEBHOOK_URL=${MS_WEBHOOK_URL}
  #   container_name: check-instance
  #   volumes:
  #     - check_instance_data_volume:/app
  #   depends_on:
  #     - prometheus
  #   restart: always

  tempo:
    image: grafana/tempo:latest
    container_name: tempo
    environment:
      - MINIO_ROOT_PASSWORD
      - MINIO_ROOT_USER
      - MINIO_BUCKET_NAME=tempo
    expose:
      - "3200"
      - "4317"
    volumes:
      - ./backends/tempo:/etc
    command:
      - "-config.file=/etc/tempo.yml"
      - "-config.expand-env=true"
    depends_on:
      - minio
    restart: unless-stopped

  otel-collector:
    image: otel/opentelemetry-collector-contrib:latest
    container_name: otel-collector
    environment:
      - MINIO_ROOT_PASSWORD
      - MINIO_ROOT_USER
      - OTEL_COLLECTOR_GRPC_RECEIVER_PORT
      - OTEL_COLLECTOR_HTTP_RECEIVER_PORT
    ports:
      - "${OTEL_COLLECTOR_GRPC_RECEIVER_PORT:-4317}:4317" # <- otlp grpc
      - "${OTEL_COLLECTOR_HTTP_RECEIVER_PORT:-4318}:4318" # <- otlp http
    expose:
      - "8889" # <- prometheus
      - "13133" # health_check extension
    volumes:
      - ./collectors/otel-collector:/etc/otel-collector
    command:
      - "--config=/etc/otel-collector/config.yml"
    depends_on:
      - minio
    restart: unless-stopped

  grafana:
    image: grafana/grafana:latest
    environment:
      - GF_APP_MODE=development
      - GF_AUTH_ANONYMOUS_ENABLED=true
      - GF_AUTH_ANONYMOUS_ORG_ROLE=Admin
    container_name: grafana
    restart: unless-stopped
    expose:
      - "3000"
    volumes:
      - "./grafana:/etc/grafana"
      - "grafana_storage:/var/lib/grafana"

  sample-app-a:
    profiles: [ "sample" ]
    build:
      context: ./test/sample-a
    restart: unless-stopped
    expose:
      - "3000"
    environment:
      - OTEL_EXPORTER_OTLP_ENDPOINT=http://otel-collector:4317
      - OTEL_RESOURCE_ATTRIBUTES=service.name=sample-app-a
      - OTEL_TRACES_EXPORTER=otlp
      - OTEL_METRICS_EXPORTER=otlp
      - OTEL_LOGS_EXPORTER=otlp
      - RABBITMQ_URI=amqp://sample-app-mq:5672
    depends_on:
      - sample-app-mq

  sample-app-mq:
    profiles: [ "sample" ]
    image: rabbitmq:4-management-alpine
    ports:
      - "15672:15672" # Admin Management
    expose:
      - "5672"
    volumes:
      - sample-app-mq-rabbitmq:/var/lib/rabbitmq
  # sample-app-b:
  #   profiles: [ "sample" ]
  #   build:
  #     context: ./test/sample-b
  #   restart: unless-stopped
  #   expose:
  #     - "3000"
  #   environment:
  #     - RABBITMQ_URI=amqp://sample-app-mq:5672
  #   depends_on:
  #     - sample-app-mq
  # k6:
  #   image: grafana/k6:latest
  #   container_name: k6
  #   # restart: unless-stopped
  #   environment:
  #     - K6_OTEL_GRPC_EXPORTER_INSECURE=true
  #     - K6_OTEL_GRPC_EXPORTER_ENDPOINT=otel-collector:4317
  #     - K6_OTEL_EXPORTER_TYPE=grpc
  #   volumes:
  #     - ./k6:/scripts
  #   command: run --out experimental-opentelemetry --http-debug=true /scripts/test.js

volumes:
  grafana_storage: {}
  minio_data_volume:
  prometheus_data_volume:
  check_instance_data_volume:
  sample-app-mq-rabbitmq:
